---
layout: post
title:  "Distributed Representations of Sentences and Documents"
date:   2018-01-04 11:59:59
author: Sungwon Lyu
categories: NLP
---
## WHY? 
한 단어의 길이는 정해져 있지만 한 문단이나 문서의 길이는 정해져 있지 않기 때문에 하나의 벡터로 만드는데 어려움이 있다. 이를 극복하기 위해 Paragraph Vector를 제안한다. 

## WHAT?
먼저 앞 단어들의 Concat나 평균으로 다음 단어를 예측하는 단어 행렬 W을 학습한다.\\
A distributed memory model: 위와 같은 예측을 하면서 맨 앞에 문단 행렬 D를 추가하여 학습한다. 이때 문단에서 일정 길이의 context를 sample하며 D를 학습한다. \\
A distributed bag of words: 문단에서 일정 길이의 context를 sample하여 문단 행렬 D로 이 문단의 단어들을 예측하는 학습을 한다. 

## So
Sentimental Analysis와 Information Retrieval 평가에서 Paragraph Vector가 압도적인 성능을 보였다. PV-DM이 PV-DBOW보다 더 나은 성능을 보이나 둘이 섞을 경우 최고의 성능을 보였다. 