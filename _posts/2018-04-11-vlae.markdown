---
layout: post
title:  "Variational Lossy Autoencoders"
date:   2018-04-11 19:53:59
author: Sungwon Lyu
categories: Generative Models
---

## WHY? 
기존의 neural autoregressive model(RNN, MADE, PixelRNN/CNN)들은 VAE의 decoder로서 부적합하다고 여겨져왔다. 왜냐하면 이 모델들의 표현력이 너무 강력해서 종종 latent variable들을 무시하고 이미지를 생성했기 때문이다. 

## WHAT?
VAE의 목적식에서 KL divergence부분은 latent variable의 posterior를 특정분포에 근사시킨다. 하지만 원래 이는 절대 달성할 수는 없는데 decoder가 표현력이 강력하면 z를 아무 의미 없게 그 분포에 근사시켜 KLD부분을 최소화 하려는 모습을 보인다. Variational Lossy Autoencoder는 decoder의 표현력을 제한시켜 z에 원하는 정보를 포함한다. 한 예시로 x가 x이전의 모든 정보를 바탕으로 다음을 예측하는 것이 아니라 제한된 window를 사용하여 local한 정보만을 습득하게 만든다면 자연스럽게 z에는 global structure의 정보가 담길 것이다. 반대로 down-sampling을 사용하여 decoder가 local정보를 제외하고 global정보만 습득한다면 z에 local정보가 담길 것이다. 또한 z의 prior분포로서 autoregressive flow를 사용하면 더욱 좋은 표현력을 가질 수 있다. 

## So?
NLL상으로 좋은 성과를 거두었다. 

[Chen, Xi, et al. "Variational lossy autoencoder." arXiv preprint arXiv:1611.02731 (2016).](https://arxiv.org/abs/1611.02731)
