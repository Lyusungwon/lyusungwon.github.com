---
layout: post
title:  "Semi-supervised Learning with Deep Generative Models"
date:   2018-05-01 11:46:59
author: Sungwon Lyu
categories: Generative Models
---

## WHY? 
Semi-supervised learning이란 적은 양의 labeled 데이터로 부터 정보를 효과적으로 generalize하여 많은 양의 unlabeled 데이터의 정보를 활용하고 이를 통하여 모델의 성능을 향상시키는 학습을 말한다. 

## WHAT?
논문에서는 세가지 모델을 제안한다. M1은 latent feature discriminative model로 모든 데이터들에 대하여 VAE를 학습시킨 후 labeled data들의 latent variable로 discriminator를 학습하여 unlabeled data를 labeling하는 것이다. 
![image](/assets/images/sdgm1.png){: .center-image width="50px"}
M2는 Generative Semi-supervised Model로 VAE를 만들 때 label y를 반영한다. unlabeled data들은 classifier를 통하여 classify를 하고 이 output을 decoder의 input으로 활용한다. 
$$log p_{\theta}(x, y) \geq E_{q_{\phi}(z|x, y)}[log p_{\theta}(x|y,z) + log p_{\theta}(y) + log p(z) - log q_{\phi}(z|x,y)] = - L(x, y)\\
log p_{\theta}(x) \geq E_{q_{\phi}(y, z|x)}[log p_{\theta}(x|y,z) + log p_{\theta}(y) + log p(z) - log q_{\phi}(y, z|x)]\\
=\Sigma_y q_{\phi}(y|x)(-L(x,y)) + H(q_{\phi}(y|x)) = -U(x, y)\\
J = \Sigma_{(x, y) \sim \tilde{p_l}} L(x,y) + \Sigma_{x \sim \tilde{p_u}} U(x)$$
이에 label데이터를 통하여 classifier를 추가로 학습시키는 항을 추가하여 다음과 같은 목적식을 가지게 된다.
$$J^{\alpha} = J + \alpha \cdot E_{\tilde{p_l}(x, y)}[-log q_{\phi}(y|x)]\\$$
![image](/assets/images/sdgm2.png){: .center-image width="50px"}
세번째 모델은 M1과 M2를 쌓아서 만든 모델로 M1을 통하여 학습한 latent variable로 M2를 학습한다. 

## So?
기존의 Semi-supervised기법에 비해 좋은 성과를 거두었으며 M1과 M2를 합친 모델이 가장 좋은 성과를 거두었다. 

## Critic
Semi supervised 논문은 처음 읽어 보았는데 현실적인 설정이라 앞으로 중요해질 분야 같다. 수식이 깔끔하고 다양한 데이터로 실험하여 좋았다. 

[Kingma, Diederik P., et al. "Semi-supervised learning with deep generative models." Advances in Neural Information Processing Systems. 2014.](http://papers.nips.cc/paper/5352-semi-supervised-learning-with-deep-generative-models)
